#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
MySQLåˆ°ClickHouseæ•°æ®æ˜ å°„å·¥å…· V3
æ”¯æŒä»MySQLæ•°æ®åº“è¯»å–æ•°æ®ï¼Œæ˜ å°„åˆ°ClickHouseåº“
æ”¯æŒè¡¨å¤‡æ³¨ã€å­—æ®µå¤‡æ³¨ã€è‡ªå¢IDæ’åºã€æ•°æ®ä¸€è‡´æ€§éªŒè¯
"""

import os
import sys
import csv
import configparser
import pymysql
from typing import List, Dict, Tuple, Optional, Any
from tqdm import tqdm
from clickhouse_driver import Client
from datetime import datetime
import pandas as pd
from dataclasses import dataclass


@dataclass
class TableMapping:
    """è¡¨æ˜ å°„ä¿¡æ¯"""
    mysql_table: str
    clickhouse_table: str
    field_mappings: Dict[str, Tuple[str, str]]  # {mysql_field: (clickhouse_field, clickhouse_type)}


@dataclass
class MigrationResult:
    """è¿ç§»ç»“æœ"""
    table_mapping: TableMapping
    success: bool
    mysql_rows: int
    clickhouse_rows: int
    error_message: str = ""
    processing_time: float = 0.0


class MySQLClient:
    """MySQLæ•°æ®åº“å®¢æˆ·ç«¯"""
    
    def __init__(self, host: str, port: int, database: str, user: str, password: str, charset: str = 'utf8mb4'):
        self.connection_config = {
            'host': host,
            'port': port,
            'database': database,
            'user': user,
            'password': password,
            'charset': charset,
            'autocommit': True
        }
        self.connection = None
    
    def connect(self):
        """è¿æ¥MySQLæ•°æ®åº“"""
        try:
            self.connection = pymysql.connect(**self.connection_config)
            print(f"âœ“ æˆåŠŸè¿æ¥åˆ°MySQLæ•°æ®åº“: {self.connection_config['host']}:{self.connection_config['port']}/{self.connection_config['database']}")
        except Exception as e:
            raise Exception(f"è¿æ¥MySQLæ•°æ®åº“å¤±è´¥: {e}")
    
    def get_table_comment(self, table_name: str) -> str:
        """è·å–è¡¨å¤‡æ³¨"""
        try:
            with self.connection.cursor() as cursor:
                cursor.execute("""
                    SELECT TABLE_COMMENT 
                    FROM information_schema.TABLES 
                    WHERE TABLE_SCHEMA = %s AND TABLE_NAME = %s
                """, (self.connection_config['database'], table_name))
                result = cursor.fetchone()
                return result[0] if result and result[0] else ""
        except Exception as e:
            print(f"è·å–è¡¨å¤‡æ³¨å¤±è´¥: {e}")
            return ""
    
    def get_table_structure(self, table_name: str) -> List[Tuple[str, str, str]]:
        """è·å–è¡¨ç»“æ„: (å­—æ®µå, æ•°æ®ç±»å‹, å¤‡æ³¨)"""
        try:
            with self.connection.cursor() as cursor:
                cursor.execute("""
                    SELECT COLUMN_NAME, DATA_TYPE, COLUMN_COMMENT 
                    FROM information_schema.COLUMNS 
                    WHERE TABLE_SCHEMA = %s AND TABLE_NAME = %s 
                    ORDER BY ORDINAL_POSITION
                """, (self.connection_config['database'], table_name))
                return cursor.fetchall()
        except Exception as e:
            raise Exception(f"è·å–è¡¨ç»“æ„å¤±è´¥: {e}")
    
    def get_table_data(self, table_name: str, batch_size: int = 1000):
        """æ‰¹é‡è·å–è¡¨æ•°æ®"""
        try:
            with self.connection.cursor() as cursor:
                cursor.execute(f"SELECT COUNT(*) FROM `{table_name}`")
                total_rows = cursor.fetchone()[0]
                
                cursor.execute(f"SELECT * FROM `{table_name}`")
                
                while True:
                    rows = cursor.fetchmany(batch_size)
                    if not rows:
                        break
                    yield rows, total_rows
        except Exception as e:
            raise Exception(f"è¯»å–è¡¨æ•°æ®å¤±è´¥: {e}")
    
    def get_table_row_count(self, table_name: str) -> int:
        """è·å–è¡¨è¡Œæ•°"""
        try:
            with self.connection.cursor() as cursor:
                cursor.execute(f"SELECT COUNT(*) FROM `{table_name}`")
                return cursor.fetchone()[0]
        except Exception as e:
            print(f"è·å–è¡¨è¡Œæ•°å¤±è´¥: {e}")
            return 0
    
    def close(self):
        """å…³é—­è¿æ¥"""
        if self.connection:
            self.connection.close()


class TypeMapper:
    """MySQLåˆ°ClickHouseç±»å‹æ˜ å°„å™¨"""
    
    TYPE_MAPPING = {
        'TINYINT': 'Int8',
        'TINYINT UNSIGNED': 'UInt8',
        'SMALLINT': 'Int16',
        'SMALLINT UNSIGNED': 'UInt16',
        'MEDIUMINT': 'Int32',
        'MEDIUMINT UNSIGNED': 'UInt32',
        'INT': 'Int32',
        'INTEGER': 'Int32',
        'INT UNSIGNED': 'UInt32',
        'INTEGER UNSIGNED': 'UInt32',
        'BIGINT': 'Int64',
        'BIGINT UNSIGNED': 'UInt64',
        'YEAR': 'Int16',
        'FLOAT': 'Float32',
        'DOUBLE': 'Float64',
        'DECIMAL': 'Decimal',
        'CHAR': 'String',
        'VARCHAR': 'String',
        'TINYTEXT': 'String',
        'TEXT': 'String',
        'MEDIUMTEXT': 'String',
        'LONGTEXT': 'String',
        'BINARY': 'String',
        'VARBINARY': 'String',
        'TINYBLOB': 'String',
        'BLOB': 'String',
        'MEDIUMBLOB': 'String',
        'LONGBLOB': 'String',
        'DATE': 'Date32',
        'TIME': 'DateTime64(6)',
        'DATETIME': 'DateTime64(6)',
        'TIMESTAMP': 'DateTime64(6)',
        'ENUM': 'LowCardinality(String)',
        'SET': 'String',
        'JSON': 'String',
        'GEOMETRY': 'String',
        'POINT': 'String',
        'LINESTRING': 'String',
        'POLYGON': 'String',
        'VECTOR': 'Array(Float32)'
    }
    
    @classmethod
    def map_mysql_type_to_clickhouse(cls, mysql_type: str) -> str:
        """å°†MySQLç±»å‹æ˜ å°„ä¸ºClickHouseç±»å‹"""
        # å¤„ç†å¸¦å‚æ•°çš„ç±»å‹ï¼Œå¦‚ VARCHAR(255), DECIMAL(10,2)
        base_type = mysql_type.upper().split('(')[0].strip()
        
        # å¤„ç†TINYINT(1)ä½œä¸ºBoolçš„ç‰¹æ®Šæƒ…å†µ
        if mysql_type.upper().startswith('TINYINT(1)'):
            return 'Bool'
        
        # å¤„ç†DECIMALç±»å‹ä¿æŒç²¾åº¦
        if base_type == 'DECIMAL' and '(' in mysql_type:
            precision_part = mysql_type[mysql_type.find('(')+1:mysql_type.find(')')]
            return f'Decimal({precision_part})'
        
        return cls.TYPE_MAPPING.get(base_type, 'String')


class CSVMappingLoader:
    """CSVæ˜ å°„æ–‡ä»¶åŠ è½½å™¨"""
    
    def __init__(self):
        self.mappings = {}
    
    def load_csv_mapping(self, csv_file: str) -> TableMapping:
        """ä»CSVæ–‡ä»¶åŠ è½½å­—æ®µæ˜ å°„å…³ç³»"""
        try:
            # ä»æ–‡ä»¶åæå–è¡¨åä¿¡æ¯
            filename = os.path.basename(csv_file)
            if '-' in filename:
                parts = filename.replace('.csv', '').split('-')
                mysql_table = parts[0]
                clickhouse_table = parts[1]
            else:
                raise ValueError(f"CSVæ–‡ä»¶åæ ¼å¼ä¸æ­£ç¡®: {filename}")
            
            field_mappings = {}
            
            with open(csv_file, 'r', encoding='utf-8') as file:
                reader = csv.DictReader(file)
                for row in reader:
                    mysql_field = row['mysql'].strip()
                    clickhouse_field = row['clickhouse'].strip()
                    # ç±»å‹æ˜ å°„å°†åœ¨åç»­æ ¹æ®MySQLå®é™…ç±»å‹ç¡®å®š
                    field_mappings[mysql_field] = (clickhouse_field, 'String')
            
            return TableMapping(
                mysql_table=mysql_table,
                clickhouse_table=clickhouse_table,
                field_mappings=field_mappings
            )
        except Exception as e:
            raise Exception(f"åŠ è½½CSVæ˜ å°„æ–‡ä»¶å¤±è´¥ {csv_file}: {e}")


class ClickHouseClientV3:
    """ClickHouseå®¢æˆ·ç«¯V3"""
    
    def __init__(self, host: str, port: int, database: str, user: str, password: str):
        self.client = Client(
            host=host,
            port=port,
            database=database,
            user=user,
            password=password
        )
        print(f"âœ“ æˆåŠŸè¿æ¥åˆ°ClickHouseæ•°æ®åº“: {host}:{port}/{database}")
    
    def drop_table_if_exists(self, table_name: str):
        """åˆ é™¤è¡¨ï¼ˆå¦‚æœå­˜åœ¨ï¼‰"""
        try:
            self.client.execute(f"DROP TABLE IF EXISTS `{table_name}`")
            print(f"âœ“ å·²åˆ é™¤è¡¨: {table_name}")
        except Exception as e:
            print(f"åˆ é™¤è¡¨å¤±è´¥: {e}")
    
    def create_table(self, table_name: str, fields: List[Tuple[str, str, str]], table_comment: str = ""):
        """åˆ›å»ºClickHouseè¡¨ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå­—æ®µä½œä¸ºä¸»é”®"""
        try:
            # æ„å»ºå­—æ®µå®šä¹‰
            field_definitions = []
            primary_key_field = None
            
            for field_name, field_type, comment in fields:
                if comment:
                    field_definitions.append(f"`{field_name}` {field_type} COMMENT '{comment}'")
                else:
                    field_definitions.append(f"`{field_name}` {field_type}")
                
                # ä½¿ç”¨ç¬¬ä¸€ä¸ªå­—æ®µä½œä¸ºä¸»é”®
                if primary_key_field is None:
                    primary_key_field = field_name
            
            # å¦‚æœæ²¡æœ‰å­—æ®µï¼Œä½¿ç”¨é»˜è®¤ä¸»é”®
            if primary_key_field is None:
                raise Exception("è¡¨å¿…é¡»è‡³å°‘åŒ…å«ä¸€ä¸ªå­—æ®µ")
            
            fields_sql = ',\n    '.join(field_definitions)
            
            # æ„å»ºè¡¨æ³¨é‡Š
            table_comment_sql = f"COMMENT '{table_comment}'" if table_comment else ""
            
            create_sql = f"""
            CREATE TABLE `{table_name}` (
                {fields_sql}
            ) ENGINE = MergeTree()
            ORDER BY `{primary_key_field}`
            {table_comment_sql}
            """
            
            self.client.execute(create_sql)
            print(f"âœ“ æˆåŠŸåˆ›å»ºè¡¨: {table_name}ï¼Œä¸»é”®å­—æ®µ: {primary_key_field}")
            
        except Exception as e:
            raise Exception(f"åˆ›å»ºè¡¨å¤±è´¥: {e}")
    
    def insert_batch(self, table_name: str, field_names: List[str], data_batch: List[List[Any]], field_types: List[str] = None):
        """æ‰¹é‡æ’å…¥æ•°æ®ï¼Œä½¿ç”¨åŸå§‹MySQLæ•°æ®"""
        try:
            # print(f"  ğŸ” å¼€å§‹å¤„ç†æ‰¹æ¬¡æ•°æ®ï¼Œè¡Œæ•°: {len(data_batch)}, å­—æ®µæ•°: {len(field_names)}")
            # if field_types:
            #     print(f"  ğŸ” å­—æ®µç±»å‹: {dict(zip(field_names, field_types))}")
            
            # å¤„ç†NULLå€¼å’Œç±»å‹è½¬æ¢ï¼Œä¸æ·»åŠ è‡ªå¢ID
            processed_data = []
            for i, row in enumerate(data_batch):
                # å¤„ç†æ¯ä¸ªå­—æ®µçš„å€¼
                processed_row = []
                for j, value in enumerate(row):
                    try:
                        field_name = field_names[j] if j < len(field_names) else f"field_{j}"
                        field_type = field_types[j] if field_types and j < len(field_types) else "String"
                        
                        if value is None:
                            # æ ¹æ®å­—æ®µç±»å‹æä¾›åˆé€‚çš„é»˜è®¤å€¼
                            default_value = self._get_default_value_for_type(field_type)
                            processed_row.append(default_value)
                            # if i < 3:  # åªè®°å½•å‰3è¡Œçš„è¯¦ç»†ä¿¡æ¯
                            #     print(f"    ğŸ” å­—æ®µ {field_name}: NULL -> {default_value} (ç±»å‹: {field_type})")
                        else:
                            # æ ¹æ®ClickHouseå­—æ®µç±»å‹è½¬æ¢å€¼
                            converted_value = self._convert_value_for_clickhouse(value, field_type, field_name)
                            processed_row.append(converted_value)
                            if i < 1:  # åªè®°å½•å‰3è¡Œçš„è¯¦ç»†ä¿¡æ¯
                                print(f"    ğŸ” å­—æ®µ {field_name}: {repr(value)} -> {repr(converted_value)} (ç±»å‹: {field_type}, Pythonç±»å‹: {type(converted_value).__name__})")
                    
                    except Exception as field_error:
                        print(f"    âš  å­—æ®µ {field_name} å¤„ç†å¤±è´¥: {field_error}, ä½¿ç”¨é»˜è®¤å€¼")
                        default_value = self._get_default_value_for_type(field_type if field_types and j < len(field_types) else "String")
                        processed_row.append(default_value)
                
                processed_data.append(processed_row)
            
            # æ’å…¥æ•°æ®
            insert_fields = field_names
            # print(f"  ğŸ” å‡†å¤‡æ’å…¥æ•°æ®: è¡¨={table_name}, å­—æ®µ={insert_fields}")
            
            # å¢åŠ è¯¦ç»†çš„æ’å…¥å‰æ£€æŸ¥
            # if processed_data:
                # print(f"  ğŸ” å³å°†æ’å…¥çš„æ•°æ®æ ·æœ¬ï¼ˆå‰2è¡Œï¼‰:")
                # for i, row in enumerate(processed_data[:2]):
                #     print(f"    è¡Œ{i+1}: {[type(val).__name__ + ':' + repr(val)[:50] + ('...' if len(repr(val)) > 50 else '') for val in row]}")
            
            try:
                self.client.execute(
                    f"INSERT INTO `{table_name}` ({', '.join(f'`{field}`' for field in insert_fields)}) VALUES",
                    processed_data
                )
                # print(f"  âœ“ æˆåŠŸæ’å…¥ {len(processed_data)} è¡Œæ•°æ®")
            except Exception as insert_error:
                print(f"  âŒ ClickHouseæ’å…¥è¯¦ç»†é”™è¯¯: {insert_error}")
                print(f"  ğŸ” é”™è¯¯ç±»å‹: {type(insert_error).__name__}")
                # print(f"  âœ“ æˆåŠŸæ’å…¥ {len(processed_data)} è¡Œæ•°æ®")
                
                # å°è¯•é€è¡Œæ’å…¥ä»¥å®šä½é—®é¢˜è¡Œ
                print(f"  ğŸ” å°è¯•é€è¡Œæ’å…¥ä»¥å®šä½é—®é¢˜...")
                for i, row in enumerate(processed_data[:5]):  # åªæ£€æŸ¥å‰5è¡Œ
                    try:
                        self.client.execute(
                            f"INSERT INTO `{table_name}` ({', '.join(f'`{field}`' for field in insert_fields)}) VALUES",
                            [row]
                        )
                        print(f"    âœ“ ç¬¬{i+1}è¡Œæ’å…¥æˆåŠŸ")
                    except Exception as row_error:
                        print(f"    âŒ ç¬¬{i+1}è¡Œæ’å…¥å¤±è´¥: {row_error}")
                        print(f"    ğŸ” é—®é¢˜è¡Œæ•°æ®: {[f'{type(val).__name__}:{repr(val)}' for val in row]}")
                        
                        # æ£€æŸ¥æ¯ä¸ªå­—æ®µå€¼
                        for j, (field, val) in enumerate(zip(insert_fields, row)):
                            if isinstance(val, str) and len(val) > 0:
                                print(f"      å­—æ®µ{field}: é•¿åº¦={len(val)}, å†…å®¹={repr(val[:100])}")
                                # æ£€æŸ¥ç‰¹æ®Šå­—ç¬¦
                                special_chars = [c for c in val if ord(c) < 32 and c not in '\t\n\r']
                                if special_chars:
                                    print(f"      âš  å‘ç°ç‰¹æ®Šå­—ç¬¦: {[hex(ord(c)) for c in special_chars[:10]]}")
                        break
                
                raise Exception(f"æ‰¹é‡æ’å…¥æ•°æ®å¤±è´¥: {insert_error}")
            
        except Exception as e:
            print(f"  âœ— æ‰¹é‡æ’å…¥å¤±è´¥: {e}")
            # æ‰“å°ç¬¬ä¸€è¡Œæ•°æ®ç”¨äºè°ƒè¯•
            if data_batch:
                print(f"  ğŸ” ç¬¬ä¸€è¡ŒåŸå§‹æ•°æ®: {data_batch[0]}")
                if 'processed_data' in locals() and processed_data:
                    print(f"  ğŸ” ç¬¬ä¸€è¡Œå¤„ç†åæ•°æ®: {processed_data[0]}")
            raise Exception(f"æ‰¹é‡æ’å…¥æ•°æ®å¤±è´¥: {e}")
    
    def _get_default_value_for_type(self, field_type: str):
        """æ ¹æ®å­—æ®µç±»å‹è·å–é»˜è®¤å€¼"""
        field_type_lower = field_type.lower()
        if any(num_type in field_type_lower for num_type in ['int', 'uint']):
            return 0
        elif any(float_type in field_type_lower for float_type in ['float', 'double']):
            return 0.0
        elif 'decimal' in field_type_lower:
            return 0
        elif field_type_lower == 'date32':
            from datetime import date
            return date(2000, 1, 1)
        elif 'datetime' in field_type_lower:
            from datetime import datetime
            return datetime(2000, 1, 1, 0, 0, 0)
        elif field_type_lower == 'bool':
            return False
        else:
            return ''
    
    def _convert_value_for_clickhouse(self, value, field_type: str, field_name: str = ""):
        """å°†MySQLå€¼è½¬æ¢ä¸ºClickHouseå…¼å®¹çš„æ ¼å¼"""
        if value is None:
            return self._get_default_value_for_type(field_type)
        
        field_type_lower = field_type.lower()
        
        try:
            # å¤„ç†æ—¥æœŸæ—¶é—´ç±»å‹
            if 'datetime' in field_type_lower or 'timestamp' in field_type_lower:
                if hasattr(value, 'strftime'):
                    # datetimeå¯¹è±¡ï¼Œç›´æ¥è¿”å›ï¼ŒClickHouseé©±åŠ¨ä¼šå¤„ç†
                    return value
                elif isinstance(value, str):
                    # å­—ç¬¦ä¸²æ ¼å¼çš„æ—¥æœŸæ—¶é—´ï¼Œå°è¯•è§£æä¸ºdatetimeå¯¹è±¡
                    try:
                        from datetime import datetime
                        # å°è¯•å¸¸è§çš„æ—¥æœŸæ—¶é—´æ ¼å¼
                        for fmt in ['%Y-%m-%d %H:%M:%S', '%Y-%m-%d %H:%M:%S.%f', '%Y-%m-%d']:
                            try:
                                return datetime.strptime(value, fmt)
                            except ValueError:
                                continue
                        # å¦‚æœéƒ½ä¸åŒ¹é…ï¼Œè¿”å›é»˜è®¤å€¼
                        return datetime(2000, 1, 1)
                    except Exception:
                        from datetime import datetime
                        return datetime(2000, 1, 1)
                else:
                    from datetime import datetime
                    return datetime(2000, 1, 1)
            
            # å¤„ç†æ—¥æœŸç±»å‹
            elif field_type_lower == 'date32':
                if hasattr(value, 'date'):
                    # dateæˆ–datetimeå¯¹è±¡ï¼Œè¿”å›dateéƒ¨åˆ†
                    return value.date() if hasattr(value, 'date') else value
                elif isinstance(value, str):
                    # å­—ç¬¦ä¸²æ ¼å¼çš„æ—¥æœŸï¼Œå°è¯•è§£æä¸ºdateå¯¹è±¡
                    try:
                        from datetime import datetime
                        for fmt in ['%Y-%m-%d', '%Y-%m-%d %H:%M:%S']:
                            try:
                                return datetime.strptime(value, fmt).date()
                            except ValueError:
                                continue
                        # å¦‚æœéƒ½ä¸åŒ¹é…ï¼Œè¿”å›é»˜è®¤å€¼
                        from datetime import date
                        return date(2000, 1, 1)
                    except Exception:
                        from datetime import date
                        return date(2000, 1, 1)
                else:
                    from datetime import date
                    return date(2000, 1, 1)
            
            # å¤„ç†æ•°å€¼ç±»å‹
            elif any(num_type in field_type_lower for num_type in ['int', 'uint']):
                if isinstance(value, (int, float)):
                    return int(value)
                elif isinstance(value, str) and value.strip():
                    try:
                        return int(float(value))  # å…ˆè½¬floatå†è½¬intï¼Œå¤„ç†å°æ•°å­—ç¬¦ä¸²
                    except (ValueError, TypeError):
                        return 0
                else:
                    return 0
            
            # å¤„ç†æµ®ç‚¹ç±»å‹
            elif any(float_type in field_type_lower for float_type in ['float', 'double', 'decimal']):
                if isinstance(value, (int, float)):
                    return float(value)
                elif isinstance(value, str) and value.strip():
                    try:
                        return float(value)
                    except (ValueError, TypeError):
                        return 0.0
                else:
                    return 0.0
            
            # å¤„ç†å¸ƒå°”ç±»å‹
            elif field_type_lower == 'bool':
                if isinstance(value, bool):
                    return value
                elif isinstance(value, (int, float)):
                    return bool(value)
                elif isinstance(value, str):
                    return value.lower() in ('true', '1', 'yes', 'on')
                else:
                    return False
            
            # å¤„ç†å­—ç¬¦ä¸²ç±»å‹
            else:
                if isinstance(value, str):
                    try:
                        # æ¸…ç†å’Œè§„èŒƒåŒ–å­—ç¬¦ä¸²
                        cleaned_value = self._clean_string_value(value)
                        return cleaned_value
                    except Exception:
                        return ''
                else:
                    return str(value)
        
        except Exception as e:
            print(f"    âš  å€¼è½¬æ¢å¤±è´¥ {field_name}: {repr(value)} -> {field_type}, é”™è¯¯: {e}")
            return self._get_default_value_for_type(field_type)
    
    def _clean_string_value(self, value: str) -> str:
        """æ¸…ç†å­—ç¬¦ä¸²å€¼ï¼Œç§»é™¤å¯èƒ½å¯¼è‡´é—®é¢˜çš„ç‰¹æ®Šå­—ç¬¦"""
        if not value:
            return ''
        
        try:
            # 1. ç§»é™¤NULLå­—ç¬¦å’Œæ§åˆ¶å­—ç¬¦
            cleaned = ''.join(char for char in value if ord(char) >= 32 or char in '\t\n\r')
            
            # 2. æ›¿æ¢å¯èƒ½æœ‰é—®é¢˜çš„å¼•å·
            cleaned = cleaned.replace('\x00', '').replace('\x01', '').replace('\x02', '')
            cleaned = cleaned.replace('\x03', '').replace('\x04', '').replace('\x05', '')
            cleaned = cleaned.replace('\x06', '').replace('\x07', '').replace('\x08', '')
            cleaned = cleaned.replace('\x0b', '').replace('\x0c', '').replace('\x0e', '')
            cleaned = cleaned.replace('\x0f', '').replace('\x10', '').replace('\x11', '')
            cleaned = cleaned.replace('\x12', '').replace('\x13', '').replace('\x14', '')
            cleaned = cleaned.replace('\x15', '').replace('\x16', '').replace('\x17', '')
            cleaned = cleaned.replace('\x18', '').replace('\x19', '').replace('\x1a', '')
            cleaned = cleaned.replace('\x1b', '').replace('\x1c', '').replace('\x1d', '')
            cleaned = cleaned.replace('\x1e', '').replace('\x1f', '')
            
            # 3. ç¡®ä¿å¯ä»¥UTF-8ç¼–ç 
            cleaned.encode('utf-8')
            
            # 4. é™åˆ¶é•¿åº¦ï¼ˆé˜²æ­¢è¿‡é•¿å­—ç¬¦ä¸²ï¼‰
            if len(cleaned) > 1000:
                cleaned = cleaned[:1000]
            
            return cleaned
        
        except Exception as e:
            print(f"    âš  å­—ç¬¦ä¸²æ¸…ç†å¤±è´¥: {repr(value)}, é”™è¯¯: {e}")
            return ''
    
    def get_table_row_count(self, table_name: str) -> int:
        """è·å–è¡¨è¡Œæ•°"""
        try:
            result = self.client.execute(f"SELECT COUNT(*) FROM `{table_name}`")
            return result[0][0]
        except Exception as e:
            print(f"è·å–ClickHouseè¡¨è¡Œæ•°å¤±è´¥: {e}")
            return 0
    
    def table_exists(self, table_name: str) -> bool:
        """æ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨"""
        try:
            result = self.client.execute(f"EXISTS TABLE `{table_name}`")
            return result[0][0] == 1
        except Exception as e:
            print(f"æ£€æŸ¥è¡¨å­˜åœ¨æ€§å¤±è´¥: {e}")
            return False
    
    def get_table_structure(self, table_name: str) -> List[Tuple[str, str, str]]:
        """è·å–è¡¨ç»“æ„ä¿¡æ¯"""
        try:
            result = self.client.execute(f"DESCRIBE TABLE `{table_name}`")
            return [(row[0], row[1], row[4] if len(row) > 4 else "") for row in result]
        except Exception as e:
            print(f"è·å–è¡¨ç»“æ„å¤±è´¥: {e}")
            return []
    
    def close(self):
        """å…³é—­è¿æ¥"""
        try:
            self.client.disconnect()
        except:
            pass


class DataMigrator:
    """æ•°æ®è¿ç§»åè°ƒå™¨"""
    
    def __init__(self, config_file: str = 'config.ini'):
        self.config = configparser.ConfigParser()
        self.config.read(config_file, encoding='utf-8')
        
        # åˆå§‹åŒ–å®¢æˆ·ç«¯
        self.mysql_client = None
        self.clickhouse_client = None
        self.csv_loader = CSVMappingLoader()
        
        # é…ç½®å‚æ•°
        self.batch_size = self.config.getint('settings', 'batch_size', fallback=1000)
        self.auto_recreate = self.config.getboolean('settings', 'auto_recreate_table', fallback=True)
        self.skip_existing = self.config.getboolean('settings', 'skip_existing_tables', fallback=False)
    
    def connect_databases(self):
        """è¿æ¥æ•°æ®åº“"""
        # è¿æ¥MySQL
        self.mysql_client = MySQLClient(
            host=self.config.get('mysql', 'host'),
            port=self.config.getint('mysql', 'port'),
            database=self.config.get('mysql', 'database'),
            user=self.config.get('mysql', 'user'),
            password=self.config.get('mysql', 'password'),
            charset=self.config.get('mysql', 'charset', fallback='utf8mb4')
        )
        self.mysql_client.connect()
        
        # è¿æ¥ClickHouse
        self.clickhouse_client = ClickHouseClientV3(
            host=self.config.get('clickhouse', 'host'),
            port=self.config.getint('clickhouse', 'port'),
            database=self.config.get('clickhouse', 'database'),
            user=self.config.get('clickhouse', 'user'),
            password=self.config.get('clickhouse', 'password')
        )
    
    def migrate_table(self, csv_file: str) -> MigrationResult:
        """è¿ç§»å•ä¸ªè¡¨çš„æ•°æ®"""
        start_time = datetime.now()
        
        try:
            # åŠ è½½æ˜ å°„é…ç½®
            table_mapping = self.csv_loader.load_csv_mapping(csv_file)
            print(f"\nå¼€å§‹è¿ç§»è¡¨: {table_mapping.mysql_table} -> {table_mapping.clickhouse_table}")
            
            # æ£€æŸ¥MySQLè¡¨æ˜¯å¦å­˜åœ¨
            mysql_row_count = self.mysql_client.get_table_row_count(table_mapping.mysql_table)
            if mysql_row_count == 0:
                print(f"âš  MySQLè¡¨ {table_mapping.mysql_table} ä¸å­˜åœ¨æˆ–ä¸ºç©º")
                return MigrationResult(
                    table_mapping=table_mapping,
                    success=False,
                    mysql_rows=0,
                    clickhouse_rows=0,
                    error_message="MySQLè¡¨ä¸å­˜åœ¨æˆ–ä¸ºç©º"
                )
            
            # æ£€æŸ¥ClickHouseè¡¨æ˜¯å¦å­˜åœ¨
            if self.clickhouse_client.table_exists(table_mapping.clickhouse_table):
                if self.skip_existing:
                    print(f"âš  ClickHouseè¡¨ {table_mapping.clickhouse_table} å·²å­˜åœ¨ï¼Œè·³è¿‡å¤„ç†")
                    return MigrationResult(
                        table_mapping=table_mapping,
                        success=True,
                        mysql_rows=mysql_row_count,
                        clickhouse_rows=self.clickhouse_client.get_table_row_count(table_mapping.clickhouse_table),
                        processing_time=(datetime.now() - start_time).total_seconds()
                    )
                elif self.auto_recreate:
                    print(f"âš  ClickHouseè¡¨ {table_mapping.clickhouse_table} å·²å­˜åœ¨ï¼Œå°†åˆ é™¤é‡å»º")
                    self.clickhouse_client.drop_table_if_exists(table_mapping.clickhouse_table)
            
            # è·å–MySQLè¡¨ç»“æ„
            mysql_structure = self.mysql_client.get_table_structure(table_mapping.mysql_table)
            table_comment = self.mysql_client.get_table_comment(table_mapping.mysql_table)
            
            # æ„å»ºClickHouseå­—æ®µå®šä¹‰
            clickhouse_fields = []
            final_field_mappings = {}
            
            for mysql_field, mysql_type, mysql_comment in mysql_structure:
                if mysql_field in table_mapping.field_mappings:
                    clickhouse_field, _ = table_mapping.field_mappings[mysql_field]
                    
                    clickhouse_type = TypeMapper.map_mysql_type_to_clickhouse(mysql_type)
                    clickhouse_fields.append((clickhouse_field, clickhouse_type, mysql_comment))
                    final_field_mappings[mysql_field] = (clickhouse_field, clickhouse_type)
            
            # åˆ›å»ºClickHouseè¡¨
            print(f"âœ“ æœ€ç»ˆæ˜ å°„å­—æ®µæ•°é‡: {len(clickhouse_fields)} (åŸMySQLè¡¨å­—æ®µæ•°: {len(mysql_structure)})")
            self.clickhouse_client.create_table(
                table_mapping.clickhouse_table,
                clickhouse_fields,
                table_comment
            )
            
            # è¿ç§»æ•°æ®
            total_migrated = 0
            progress_bar = tqdm(total=mysql_row_count, desc=f"è¿ç§»æ•°æ®")
            print(f"å¼€å§‹è¿ç§»æ•°æ®ï¼Œæ€»è®¡ {mysql_row_count} è¡Œï¼Œæ‰¹æ¬¡å¤§å°: {self.batch_size}")
            
            batch_count = 0
            for batch_data, _ in self.mysql_client.get_table_data(table_mapping.mysql_table, self.batch_size):
                batch_count += 1
                # print(f"\nğŸ“¦ å¤„ç†ç¬¬ {batch_count} æ‰¹æ¬¡ï¼Œè¡Œæ•°: {len(batch_data)}")
                # é‡æ–°æ’åºæ•°æ®ä»¥åŒ¹é…å­—æ®µæ˜ å°„ï¼ŒåŒæ—¶å¿½ç•¥è¢«è¿‡æ»¤çš„idå­—æ®µ
                mapped_data = []
                if batch_count == 1:  # åªåœ¨ç¬¬ä¸€æ‰¹æ¬¡æ‰“å°è¯¦ç»†æ˜ å°„ä¿¡æ¯
                    print(f"  ğŸ” å­—æ®µæ˜ å°„è¯¦æƒ…:")
                    for i, (mysql_field, mysql_type, _) in enumerate(mysql_structure):
                        if mysql_field in final_field_mappings:
                            ch_field, ch_type = final_field_mappings[mysql_field]
                            print(f"    {i}: {mysql_field}({mysql_type}) -> {ch_field}({ch_type})")
                        else:
                            print(f"    {i}: {mysql_field}({mysql_type}) -> [è·³è¿‡]")
                
                for row_idx, row in enumerate(batch_data):
                    mapped_row = []
                    for i, (mysql_field, mysql_type, _) in enumerate(mysql_structure):
                        if mysql_field in final_field_mappings:
                            mapped_row.append(row[i])
                    mapped_data.append(mapped_row)
                    
                    # æ‰“å°ç¬¬ä¸€è¡Œæ•°æ®çš„è¯¦ç»†ä¿¡æ¯
                    if batch_count == 1 and row_idx == 0:
                        print(f"  ğŸ” ç¬¬ä¸€è¡ŒåŸå§‹æ•°æ®é•¿åº¦: {len(row)}")
                        print(f"  ğŸ” ç¬¬ä¸€è¡Œæ˜ å°„æ•°æ®é•¿åº¦: {len(mapped_row)}")
                        for i, (mysql_field, mysql_type, _) in enumerate(mysql_structure):
                            if mysql_field in final_field_mappings:
                                ch_field, ch_type = final_field_mappings[mysql_field]
                                value = row[i] if i < len(row) else "è¶Šç•Œ"
                                print(f"    {mysql_field}={repr(value)} -> {ch_field}({ch_type})")
                
                # print(f"  ğŸ“Š æ˜ å°„å®Œæˆ: {len(batch_data)} è¡Œ -> {len(mapped_data)} è¡Œï¼Œæ¯è¡Œå­—æ®µæ•°: {len(mapped_data[0]) if mapped_data else 0}")
                
                # æ’å…¥åˆ°ClickHouseï¼ŒåªåŒ…å«æœ€ç»ˆæ˜ å°„çš„å­—æ®µ
                clickhouse_field_names = [final_field_mappings[field][0] for field, _, _ in mysql_structure if field in final_field_mappings]
                clickhouse_field_types = [final_field_mappings[field][1] for field, _, _ in mysql_structure if field in final_field_mappings]
                self.clickhouse_client.insert_batch(
                    table_mapping.clickhouse_table,
                    clickhouse_field_names,
                    mapped_data,
                    clickhouse_field_types
                )
                
                total_migrated += len(mapped_data)
                progress_bar.update(len(mapped_data))
            
            progress_bar.close()
            
            # éªŒè¯è¿ç§»ç»“æœ
            clickhouse_row_count = self.clickhouse_client.get_table_row_count(table_mapping.clickhouse_table)
            
            result = MigrationResult(
                table_mapping=table_mapping,
                success=True,
                mysql_rows=mysql_row_count,
                clickhouse_rows=clickhouse_row_count,
                processing_time=(datetime.now() - start_time).total_seconds()
            )
            
            print(f"âœ“ è¿ç§»å®Œæˆ: MySQL({mysql_row_count}è¡Œ) -> ClickHouse({clickhouse_row_count}è¡Œ)")
            return result
            
        except Exception as e:
            return MigrationResult(
                table_mapping=table_mapping if 'table_mapping' in locals() else None,
                success=False,
                mysql_rows=0,
                clickhouse_rows=0,
                error_message=str(e),
                processing_time=(datetime.now() - start_time).total_seconds()
            )
    
    def migrate_all_tables(self, csv_directory: str = "./clickhouse_mapper") -> List[MigrationResult]:
        """è¿ç§»æ‰€æœ‰CSVé…ç½®çš„è¡¨"""
        csv_files = [f for f in os.listdir(csv_directory) if f.endswith('.csv')]
        
        if not csv_files:
            print("æœªæ‰¾åˆ°CSVæ˜ å°„æ–‡ä»¶")
            return []
        
        print(f"å‘ç° {len(csv_files)} ä¸ªCSVæ˜ å°„æ–‡ä»¶")
        results = []
        
        for csv_file in csv_files:
            csv_path = os.path.join(csv_directory, csv_file)
            result = self.migrate_table(csv_path)
            results.append(result)
        
        return results
    
    def print_migration_summary(self, results: List[MigrationResult]):
        """æ‰“å°è¿ç§»æ±‡æ€»"""
        print("\n" + "="*80)
        print("è¿ç§»æ±‡æ€»æŠ¥å‘Š")
        print("="*80)
        
        successful_migrations = [r for r in results if r.success]
        failed_migrations = [r for r in results if not r.success]
        
        print(f"æ€»è®¡è¡¨æ•°: {len(results)}")
        print(f"æˆåŠŸè¿ç§»: {len(successful_migrations)}")
        print(f"å¤±è´¥æ•°é‡: {len(failed_migrations)}")
        
        if successful_migrations:
            print(f"\næˆåŠŸè¿ç§»çš„è¡¨:")
            for result in successful_migrations:
                print(f"  âœ“ {result.table_mapping.mysql_table} -> {result.table_mapping.clickhouse_table}")
                print(f"    MySQLè¡Œæ•°: {result.mysql_rows}, ClickHouseè¡Œæ•°: {result.clickhouse_rows}")
                print(f"    å¤„ç†æ—¶é—´: {result.processing_time:.2f}ç§’")
        
        if failed_migrations:
            print(f"\nå¤±è´¥çš„è¡¨:")
            for result in failed_migrations:
                table_name = result.table_mapping.mysql_table if result.table_mapping else "æœªçŸ¥"
                print(f"  âœ— {table_name}: {result.error_message}")
    
    def close(self):
        """å…³é—­æ‰€æœ‰è¿æ¥"""
        if self.mysql_client:
            self.mysql_client.close()
        if self.clickhouse_client:
            self.clickhouse_client.close()


def main():
    """ä¸»å‡½æ•°"""
    print("MySQLåˆ°ClickHouseæ•°æ®æ˜ å°„å·¥å…· V3")
    print("="*50)
    
    migrator = DataMigrator()
    
    try:
        # è¿æ¥æ•°æ®åº“
        print("æ­£åœ¨è¿æ¥æ•°æ®åº“...")
        migrator.connect_databases()
        
        # æ‰§è¡Œè¿ç§»
        results = migrator.migrate_all_tables()
        
        # æ‰“å°æ±‡æ€»
        migrator.print_migration_summary(results)
        
    except Exception as e:
        print(f"è¿ç§»è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
    finally:
        migrator.close()


if __name__ == "__main__":
    main() 